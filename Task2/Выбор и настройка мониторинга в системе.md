# Выбор и настройка мониторинга в системе

## Контекст

До открытия внешнего API бизнес опирался на Яндекс Метрику и жалобы пользователей. После появления B2B-сценариев (оформление заказов через API) Метрика перестала отражать значимую часть нагрузки и проблем: она видит только фронт онлайн-магазина, но не видит здоровье API, очередей, расчётов стоимости и “зависаний” заказов на уровне интеграций.

Цель этого документа — определить **что измеряем**, **где измеряем** и **как это обосновать бизнесу**, чтобы:
- находить причины задержек заказов и “потерь” в процессе;
- видеть деградации до того, как придут жалобы и уйдут контракты;
- планировать масштабирование на фактах.

---

## 1) Мотивация

Мониторинг нужен не “ради красивых графиков”, а чтобы вернуть управляемость бизнеса:

1) **Сократить потери денег и контрактов**
- Сейчас жалобы идут ежедневно (B2B и B2C), уже потеряны контракты.
- Без мониторинга команда узнаёт о проблемах поздно (по обращениям), а значит время простоя и недовольства максимальное.

2) **Снизить время поиска причин (MTTR)**
- При распределённой архитектуре (Shop ↔ MES ↔ CRM ↔ RabbitMQ ↔ S3) проблема может быть в любом звене.
- Нужны метрики, чтобы за 10–15 минут понять: “очередь растёт”, “консьюмер упал”, “БД упёрлась в коннекты”, “расчёт цены забил CPU”.

3) **Контролировать критичный бизнес-процесс “заказ”**
- Важно видеть не только технику (CPU/память), но и **процесс**: сколько заказов застряло в статусе, где образуется очередь, сколько времени занимает расчёт/подтверждение/производство.

4) **Принять правильные решения по масштабированию**
- Сейчас “нагрузка растёт линейно”, а инстансы по одному.
- Мониторинг даст измеримые ответы: *что именно стало узким местом* и *что даст максимальный эффект*.

Результат для бизнеса: меньше сорванных сроков и жалоб, меньше “пожаров”, быстрее релизы и предсказуемое развитие под рост заказов.

---

## 2) Выбор подхода к мониторингу

Для разных частей системы разумно использовать разные подходы:

### 2.1. Для API (Shop API, CRM API, MES API) — **RED**
RED хорошо отвечает на вопрос: “API живой и справляется?”
- **R**ate — сколько запросов приходит (нагрузка)
- **E**rrors — сколько ошибок и каких
- **D**uration — как долго отвечает (latency)

Это напрямую связано с пользовательским опытом и SLA.

### 2.2. Для инфраструктуры/ресурсов (EC2, DB, воркеры) — **USE**
USE отвечает на вопрос: “в какой ресурс упираемся?”
- **U**tilization — насколько занят ресурс (CPU, память, диск)
- **S**aturation — есть ли очередь ожидания (например, коннекты к БД, I/O wait)
- **E**rrors — ошибки на уровне ресурса/сервиса

### 2.3. Для асинхронной интеграции (RabbitMQ) — смесь **RED + USE**
Для очередей важно:
- скорость поступления/обработки,
- рост “хвоста” (backlog),
- DLQ/DLX и возраст сообщений.

### 2.4. Для бизнес-процесса заказа — “сигналы процесса”
Это не классический RED/USE, но без этого мы не найдём “заказ завис на месяцы”.  
Здесь нужен набор **процессных метрик**: время в статусах, количество заказов в статусах, доля просроченных.

---

## 3) Метрики: что отслеживаем и зачем

Ниже перечислены выбранные метрики (из предложенного списка) + добавленные метрики, которые критичны для кейса.

### Общие ярлыки (labels), которые стоит стандартизировать
Эти ярлыки помогают разрезать графики и быстро находить причины:
- `env` (dev/release/prod)
- `service` (shop-api, crm-api, mes-api, price-worker и т.п.)
- `instance` (инстанс/host)
- `endpoint` / `route` (для HTTP)
- `method` (GET/POST/…)
- `status_code` или `status_class` (2xx/4xx/5xx)
- `client_type` (b2c/b2b)
- `api_client_id` (для внешнего API, если есть идентификатор клиента)
- `queue` / `exchange` / `routing_key` (для RabbitMQ)
- `db` (shop-db/mes-db)
- `order_status` (для процессных метрик)

---

## 3.1. Интернет-магазин (Shop API)

#### Number of requests (RPS) for internet shop API
- **Зачем:** понимать текущую нагрузку, пики, тренд роста.
- **Ярлыки:** `env`, `endpoint`, `method`, `client_type` (в основном b2c).

#### Number of requests (RPS) per user for internet shop API
- **Зачем:** находить аномалии/скрейпинг/злоупотребления, понять нагрузку на пользователя.
- **Ярлыки:** `user_id` (или анонимный/хэш), `endpoint`, `env`.

#### Response time (latency) for shop API
- **Зачем:** контролировать производительность, коррелировать с жалобами, выделять p95/p99.
- **Ярлыки:** `endpoint`, `method`, `env`.

#### Number of HTTP 200 / Number of HTTP 500 for shop API
- **Зачем:** видеть ошибки и деградации, считать error rate.
- **Ярлыки:** `endpoint`, `env`, `error_type` (если возможно: validation/timeout/db).

#### CPU % / Memory Utilisation for shop API
- **Зачем:** выявлять упор в ресурсы, утечки памяти, необходимость масштабирования.
- **Ярлыки:** `instance`, `env`.

#### (Дополнительно) Conversion/funnel метрика по шагам заказа
- **Зачем:** отделить “проблема UX” от “проблема бэкенда”, видеть провалы: INITIATED → FILE_UPLOADED → SUBMITTED.
- **Ярлыки:** `env`, `client_type`.

---

## 3.2. CRM (CRM API)

#### Number of requests (RPS) for CRM API
- **Зачем:** понимать нагрузку со стороны продавцов и интеграций (включая сообщения из RabbitMQ).
- **Ярлыки:** `endpoint`, `env`, `client_type` (внутренний/интеграционный).

#### Response time (latency) for CRM API
- **Зачем:** видеть деградации, которые задерживают статус MANUFACTURING_APPROVED / CLOSED.
- **Ярлыки:** `endpoint`, `env`.

#### Number of HTTP 200 / Number of HTTP 500 for CRM API
- **Зачем:** контроль ошибок, быстрый сигнал “сломалось”.
- **Ярлыки:** `endpoint`, `env`, `error_type`.

#### CPU % / Memory Utilisation for CRM API
- **Зачем:** упор в ресурсы при росте заказов (особенно после B2B).
- **Ярлыки:** `instance`, `env`.

#### Number of simultanious sessions for CRM API
- **Зачем:** понять нагрузку от продавцов и админов в пиковые часы.
- **Ярлыки:** `env`.

---

## 3.3. MES (MES API)

MES — критичный узел: расчёт цены, “первый экран” для операторов, статусы производства.

#### Number of requests (RPS) for MES API
- **Зачем:** понять нагрузку от операторов и внутренних сценариев.
- **Ярлыки:** `endpoint`, `env`.

#### Number of requests (RPS) per user for MES API
- **Зачем:** выявить “тяжёлых пользователей”/аномалии (например, массовые обновления UI).
- **Ярлыки:** `operator_id`, `endpoint`, `env`.

#### Response time (latency) for MES API
- **Зачем:** ключевой показатель “тормозит ли MES”, особенно для “первой страницы”.
- **Ярлыки:** `endpoint`, `env`.  
  Для дашборда отдельно: `endpoint=/orders/dashboard` (или аналог).

#### Number of HTTP 200 / Number of HTTP 500 for MES API
- **Зачем:** контроль деградации и ошибок расчёта/выдачи списка заказов.
- **Ярлыки:** `endpoint`, `env`, `error_type`.

#### CPU % / Memory Utilisation for MES API
- **Зачем:** проверить гипотезу, что тяжёлые расчёты/фоновые операции забивают ресурсы и тормозят UI.
- **Ярлыки:** `instance`, `env`.

#### Number of simultanious sessions for MES API
- **Зачем:** увидеть реальную одновременную работу операторов и соотнести с производительностью.
- **Ярлыки:** `env`.

#### (Дополнительно) Метрики расчёта цены (обязательные для кейса)
1) `price_calc_duration_seconds` (p50/p95/p99)
- **Зачем:** это главная тяжёлая операция, влияет на SLA и жалобы.
- **Ярлыки:** `env`, `client_type` (b2c/b2b), `complexity_bucket` (например: low/medium/high по полигонам).

2) `price_calc_queue_depth` (если расчёт вынесен в очередь)
- **Зачем:** ранний сигнал “мы не успеваем считать”.
- **Ярлыки:** `env`, `client_type`.

3) `price_calc_errors_total`
- **Зачем:** видеть сбои в расчёте (битые файлы, таймауты, ошибки зависимостей).
- **Ярлыки:** `env`, `error_type`, `client_type`.

---

## 3.4. RabbitMQ (интеграция CRM ↔ MES)

#### Number of dead-letter-exchange letters in RabbitMQ
- **Зачем:** прямой показатель “сообщения не обрабатываются”, возможная причина “зависших” заказов.
- **Ярлыки:** `env`, `queue`, `exchange`, `routing_key`, `consumer`.

#### Number of message in flight in RabbitMQ
- **Зачем:** понять, сколько сообщений “в процессе” и не подтверждено (ack), риск роста хвоста.
- **Ярлыки:** `env`, `queue`, `consumer`.

#### (Дополнительно, очень желательно) Queue depth / message age
1) `rabbitmq_queue_messages_ready`
- **Зачем:** backlog — если растёт, система не успевает.
- **Ярлыки:** `env`, `queue`.

2) `rabbitmq_queue_message_age_seconds` (или оценка возраста по timestamp)
- **Зачем:** бизнес-важно: “сообщение лежит уже 3 часа” = риск просрочки.
- **Ярлыки:** `env`, `queue`.

#### (Дополнительно) Rate публикации/потребления
- **Зачем:** видеть, кто является узким местом (producer или consumer).
- **Ярлыки:** `env`, `queue`, `producer`, `consumer`.

---

## 3.5. Хранилище 3D-файлов (S3)

#### Size of S3 storage
- **Зачем:** контроль роста затрат и потенциальных проблем хранения/жизненного цикла файлов.
- **Ярлыки:** `env`, `bucket`, `client_type` (b2c/b2b), `file_type` (model/preview).

#### (Дополнительно) Ошибки загрузки/доступа к файлам
- **Зачем:** если 3D-файл недоступен/битый, расчёт цены и заказ ломаются.
- **Ярлыки:** `env`, `operation` (upload/download), `error_type`.

#### (Дополнительно) Время загрузки файла
- **Зачем:** влияет на воронку заказа и UX.
- **Ярлыки:** `env`, `client_type`, `file_size_bucket`.

---

## 3.6. Базы данных (Shop DB, MES DB)

#### Memory Utilisation for shop db instance / MES db instance
- **Зачем:** признаки упора в ресурсы, риск деградации.
- **Ярлыки:** `env`, `db`.

#### Number of connections for shop db instance / MES db instance
- **Зачем:** частая причина “всё тормозит”: исчерпали пул коннектов или неправильный pooling.
- **Ярлыки:** `env`, `db`, `app` (кто создаёт коннекты).

#### Size of shop db instance / Size of MES db instance
- **Зачем:** контроль роста, планирование обслуживания (VACUUM/архивация), риск падения производительности.
- **Ярлыки:** `env`, `db`.

#### (Дополнительно) Метрики Postgres, которые желательно добавить
1) `pg_stat_statements` (top queries по времени/IO)
- **Зачем:** точное понимание, почему “первая страница MES” тормозит.
- **Ярлыки:** `db`, `queryid` (внутренний), `app`.

2) `cache_hit_ratio`, `slow_queries_total`, `locks_waiting`
- **Зачем:** диагностика деградаций и блокировок.
- **Ярлыки:** `db`, `env`.

---

## 3.7. Процессные метрики заказа (то, чего нет в Метрике)

Эти метрики нужно собрать на уровне бэкендов/БД (или отдельного “процессного” сервиса).

1) `orders_created_total` и `orders_by_status` (гейджи по статусам)
- **Зачем:** видеть распределение и “бутылочное горлышко” (например, много SUBMITTED, мало PRICE_CALCULATED).
- **Ярлыки:** `env`, `client_type`, `order_status`.

2) `order_time_in_status_seconds` (гистограмма)
- **Зачем:** прямо отвечает на бизнес-вопрос “почему делаем месяцами”.
- **Ярлыки:** `env`, `client_type`, `order_status`.

3) `orders_stuck_total` (например: “не менял статус > N часов/дней”)
- **Зачем:** раннее обнаружение реальных проблем в процессе.
- **Ярлыки:** `env`, `client_type`, `order_status`.

4) `b2b_orders_total` и `b2b_order_errors_total`
- **Зачем:** API-сегмент сейчас самый болезненный; бизнесу важна отдельная видимость.
- **Ярлыки:** `api_client_id`, `env`, `error_type`.

---

## 4) План действий 

Ниже — минимально достаточный план, чтобы мониторинг начал приносить пользу быстро, и дальше расширялся.

### Этап 0. Договориться о целях и ответственности (1–2 дня)
- Зафиксировать список SLO/алертов, которые важны бизнесу:
  - “ошибки API > X%”
  - “очередь растёт”
  - “расчёт цены p95 > N минут”
  - “заказ застрял в статусе > N дней”
- Назначить владельцев дашбордов/алертов (DevOps + ответственные разработчики).

### Этап 1. Выбрать и развернуть стек метрик (1 неделя)
- Создать инстанс time-series базы и мониторинга:
  - вариант A: managed мониторинг (если доступен в облаке),
  - вариант B: Prometheus + Grafana + Alertmanager (self-hosted).
- Настроить хранение метрик, ретеншн, доступы.
- Настроить базовые алерты (доступность компонентов).

### Этап 2. Инструментировать сервисы (2–3 недели)
- Shop API / CRM API (Spring Boot): включить метрики через стандартный механизм (например, actuator/micrometer) и экспорт в Prometheus.
- MES API (C#): добавить Prometheus-метрики (middleware).
- Принять единый формат лейблов (`env`, `service`, `endpoint`, `client_type`).
- Добавить метрики “ошибки”, “латентность”, “RPS” (RED) + ресурсы (USE).

### Этап 3. RabbitMQ и Postgres экспортеры (1 неделя)
- Подключить RabbitMQ exporter:
  - DLQ/DLX, in-flight, backlog, возраст сообщений.
- Подключить Postgres exporter:
  - коннекты, память, размер, основные показатели,
  - включить сбор `pg_stat_statements` (для расследований performance).

### Этап 4. Дашборды и алерты под боли бизнеса (1–2 недели)
- Дашборд “Здоровье заказа”: количество заказов по статусам, время в статусах, stuck orders.
- Дашборд “MES Operators”: latency дашборда/списка заказов, RPS, ошибки.
- Дашборд “Price calculation”: длительность, очередь, ошибки.
- Дашборд “Integration”: backlog RabbitMQ, DLQ, скорость потребления.

Алерты (первые, самые полезные):
- DLQ > 0 (или растёт) — **P1**
- backlog/age сообщений > порога — **P1**
- error rate 5xx по любому API > порога — **P1**
- p95 latency MES API (дашборд) > порога — **P1/P2**
- price_calc p95 > порога / очередь расчёта растёт — **P1**
- DB connections > 80% пула — **P1/P2**
- orders_stuck_total > 0 или растёт — **P1**

### Этап 5. Процессные метрики и регулярная сверка (2–4 недели)
- Реализовать сбор метрик “время в статусе” и “застрявшие заказы”:
  - либо через запросы к БД и экспорт в метрики,
  - либо через отдельную джобу (cron/worker).
- Привязать к alerting + runbook (“что делаем, когда заказ завис”).

### Этап 6. Организационная часть (параллельно)
- Написать короткие runbook’и на P1 алерты (куда смотреть, что проверять).
- Обучить команду: как пользоваться дашбордами, как фиксировать причины (postmortem).
- Ввести регулярный разбор метрик (раз в неделю) и связь с backlog’ом задач.

---

## Критерии успеха (для бизнеса)

Через 4–6 недель после внедрения базового мониторинга компания должна увидеть:
- уменьшение “слепых зон” по B2B API (видно, где тормозит/падает);
- сокращение времени реакции на инциденты (MTTR);
- уменьшение количества заказов, зависших без движения (stuck orders);
- понятные причины тормозов MES (БД/ресурсы/код), а не гипотезы.


