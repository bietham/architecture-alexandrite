# Архитектурное решение по логированию

## 0) Цель

Сделать так, чтобы по **order_id** (и для B2B по **api_client_id**) команда поддержки и разработчики могли за минуты понять:
- что произошло с заказом;
- в каком сервисе и на каком шаге возникла ошибка/аномалия;
- какие события/сообщения были обработаны, повторены или ушли в DLQ.

Логирование должно дополнять мониторинг и трейсинг:  
- **метрики** показывают “что деградирует”,  
- **трейсы** показывают путь одного заказа,  
- **логи** дают детали “почему упало” и “что было внутри”.

---

## 1) Анализ системы: откуда собирать логи и где чаще “ломается”

По C4 и описанию процесса заказы чаще всего ломаются/зависают в следующих точках:
- **Shop API**: создание заказа, загрузка 3D-файла, сабмит заказа, публикация события.
- **RabbitMQ**: доставка и обработка событий, ретраи, DLQ.
- **MES API**: расчёт цены (долго), доступ к S3, обновления статусов производства, выдача списка заказов (дашборд).
- **CRM API**: подтверждение производства, закрытие заказа, обработка событий.
- **S3**: ошибки upload/download 3D-моделей, проблемы доступов/ключей.
- **PostgreSQL (Shop DB, MES DB)**: долгие запросы, блокировки, исчерпание коннектов.

### 1.1. Системы, из которых требуется сбор логов (отметить на схеме)
**Собирать логи нужно из:**
- Shop API (Spring Boot)
- CRM API (Spring Boot)
- MES API (C#)
- RabbitMQ (broker logs + при необходимости DLQ/queue events)
- Инстансы/хосты (system logs: CPU pressure, OOM, disk)
- (опционально) Nginx/Ingress/Load balancer (если есть) — access logs
- (опционально) S3 audit/access logs (если доступны в облаке)

> Фронтенд-логи (браузер) — не первоочередные, но позже можно добавить клиентский error tracking (например, Sentry).

---

## 2) Список необходимых логов уровня INFO

Ниже — список событий, которые нужно логировать на уровне **INFO**.  
Формат логов — структурированный JSON (ключи одинаковые для всех сервисов).  
Обязательные поля в каждом INFO-логе: `timestamp`, `level`, `service`, `env`, `trace_id` (если есть), `order_id` (если известен), `message_id` (для очереди), `api_client_id` (для B2B), `event` (тип события), `duration_ms` (если применимо), `result` (OK/FAIL).

### 2.1. Shop API (B2C)
1) **Создание заказа / INITIATED**
- Что логируем: `order_id`, `customer_id` (лучше псевдо/хэш), `source=b2c`, `cart_size`, `result`.

2) **Загрузка 3D-файла / FILE_UPLOADED**
- `order_id`, `file_id` (без полного S3 key), `file_size_bytes`, `upload_duration_ms`, `result`.

3) **Оформление заказа / SUBMITTED**
- `order_id`, `customer_id`, `source=b2c`, `result`.
- Если публикуем событие в RabbitMQ: `exchange`, `routing_key`, `message_id`, `publish_result`.

4) **Публикация событий**
- Любая отправка сообщения в RabbitMQ: `message_id`, `event_type`, `order_id`, `exchange/queue`, `publish_result`.

### 2.2. CRM API
1) **Получение события из RabbitMQ (consumer)**
- `message_id`, `event_type`, `order_id`, `queue`, `delivery_attempt`, `result` (ACK/RETRY/DLQ).

2) **Смена статуса заказа в CRM: MANUFACTURING_APPROVED / CLOSED**
- `order_id`, `status_prev`, `status_new`, `actor` (seller/admin/system), `result`.

3) **Ошибки обработки бизнес-правил (но на INFO фиксируем факт отказа)**
- Например, “нельзя подтвердить производство”: `order_id`, `reason_code`, `result=REJECTED`.

4) **Публикация событий в RabbitMQ (producer)**
- `message_id`, `event_type`, `order_id`, `exchange/queue`, `publish_result`.

### 2.3. MES API
1) **Старт расчёта цены (PRICE_CALCULATED — процесс)**
- `order_id`, `source` (b2c/b2b), `file_id`, `model_complexity` (если известно), `calc_started=true`.

2) **Завершение расчёта цены**
- `order_id`, `calc_duration_ms`, `result`, (опционально) `price_value` — осторожно, можно без суммы в логах или в “маске”.

3) **Чтение 3D-файла из S3**
- `order_id`, `file_id`, `operation=download`, `duration_ms`, `result`.

4) **Смена статусов производства**
- `order_id`, `status_prev`, `status_new` (MANUFACTURING_STARTED/COMPLETED, PACKAGING, SHIPPED), `operator_id`, `result`.

5) **Захват заказа оператором (claim)**
- `order_id`, `operator_id`, `result` (SUCCESS/ALREADY_TAKEN/CONFLICT), `duration_ms`.

6) **Запрос дашборда / список заказов**
- `operator_id`, `filters` (статусы), `page_size`, `query_duration_ms`, `result`, `rows_returned`.

7) **Публикация/получение событий RabbitMQ**
- как и в CRM: `message_id`, `event_type`, `order_id`, `result` (ACK/RETRY/DLQ).

### 2.4. RabbitMQ (broker / системные события)
1) **События DLQ / DLX**
- `queue`, `exchange`, `routing_key`, `message_id`, `reason`.

2) **Проблемы коннектов/каналов**
- `connection_id`, `client`, `reason`.

3) **Ресурсные предупреждения**
- `memory_alarm`, `disk_alarm`, `cluster_partition` (если применимо).

### 2.5. Базы данных и системные логи
- Postgres slow query logs (в отдельный канал/индекс), где возможно:
  - `duration_ms`, `db`, `app_name`, `query_id` (не полный SQL).
- Системные события инстансов:
  - рестарты сервисов, OOM kills, нехватка диска, падения процессов.

---

## 3) Другие уровни логирования: когда и как

### DEBUG
- Использовать **только**:
  - в dev/release окружениях,
  - временно в prod по feature-flag на короткое время для расследования (с авто-выключением).
- DEBUG не должен содержать PII и payload.

### WARN
- Нестандартные, но не фатальные ситуации:
  - ретраи сообщений,
  - превышение времени ответа (timeout approaching),
  - деградация зависимостей (S3 slow),
  - конфликты claim заказа, частые 409.

### ERROR
- Ошибки, требующие внимания:
  - падение обработки события,
  - невозможность прочитать файл,
  - ошибка БД,
  - исключения бизнес-логики, приводящие к “застреванию” заказа.

### FATAL/CRITICAL (если используется)
- Сервис не может продолжать работу (например, миграции сломаны, нет доступа к БД).

---

## 4) Мотивация

### 4.1. Почему логирование нужно добавить
- Сейчас расследования идут “со слов клиента”, значит:
  - команда тратит часы/дни на воспроизведение,
  - нет объективной картины,
  - поддержка перегружена, а бизнес теряет деньги из-за задержек.
- Логи — самый дешёвый и быстрый способ получить “детали” без доработки бизнес-функций.

### 4.2. Что это даст компании
- Быстрые ответы клиентам и B2B партнёрам (“заказ на шаге X, причина Y”).
- Сокращение времени на расследование и починку.
- Основа для аномалий и алертов (раньше узнаём о проблеме).

### 4.3. Метрики, на которые повлияет логирование (3–5)
Технические:
1) **MTTR** — уменьшится за счёт точной диагностики.
2) **Incident rate / повторяемость инцидентов** — станет измеримой (по сигнатурам ошибок).
3) **Error budget / error rate** — проще контролировать по типам ошибок.

Бизнес:
4) **Количество обращений в поддержку по статусу заказа** — снизится.
5) **Доля просроченных заказов** — снижается за счёт быстрого обнаружения “зависаний” и причин.

---

## 5) Приоритет внедрения: логирование и трейсинг в первую очередь

Команда не может сделать всё сразу, поэтому приоритизация должна бить по основным болям: “заказы теряются/зависают”, “MES тормозит”, “B2B жалуется”.

### 5.1. Первые системы для логирования (и почему)
1) **MES API**
- Критичен для расчёта цены и статусов производства.
- Здесь чаще всего будут “тяжёлые” ошибки: S3, расчёт, БД, дашборд.

2) **RabbitMQ (и consumer/producer логи в CRM/MES)**
- В кейсе явно звучит “сообщения теряются”.
- Нужно видеть retry/DLQ/ack и связать это с order_id/message_id.

3) **CRM API**
- Важен для MANUFACTURING_APPROVED и CLOSED, без него заказ “не завершится”.

4) **Shop API**
- Важен, но чаще проблемы “после сабмита”, когда начинается межсервисный процесс.

### 5.2. Первые системы для трейсинга (в том же порядке)
- **MES API + RabbitMQ + CRM API** — дают максимальную видимость “где зависло”.
- Shop API можно подключить сразу, если не дорого, но минимум — цепочка MES↔CRM через очередь.

---

## 6) Предлагаемое решение

### 6.1. Технологии и компоненты
Базовый вариант (универсальный и быстрый):
- **Сбор логов агентом** на инстансах: Fluent Bit / Vector / Filebeat.
- **Центральное хранилище и поиск**:
  - вариант A: Grafana Loki + Grafana (лог-агрегация и поиск),
  - вариант B: Elasticsearch/OpenSearch + Kibana/OpenSearch Dashboards.
- **Корреляция**:
  - обязательные поля `trace_id` и `order_id` в логах,
  - единый JSON-формат (structured logging).

Рекомендация по выбору:
- Если уже планируется Grafana для метрик/трейсов — **Loki** обычно проще и дешевле в эксплуатации.
- Если нужен мощный полнотекст и сложные запросы по полям — **OpenSearch/Elasticsearch**.

### 6.2. Что дорабатываем в сервисах
- Включаем structured logging (JSON).
- Прописываем единый набор полей (см. раздел 2).
- В middleware добавляем автоматическую вставку `trace_id` (из OTel) в лог-контекст.
- Для очереди: логируем `message_id`, `queue`, `routing_key`, `result` (ACK/RETRY/DLQ).

### 6.3. Что добавляем на схему (как правки к C4, без отрисовки)
Новые элементы (выделить **красным**):
1) **Log Collector Agent** (на инстансах) — Fluent Bit/Vector/Filebeat
2) **Log Backend** (Loki или OpenSearch/Elasticsearch)
3) **Log UI** (Grafana или Kibana)
4) (опционально) **Alerting** (Grafana Alerting / Alertmanager / Elastalert)

Новые связи (красным):
- Shop API / CRM API / MES API / RabbitMQ / system logs → Log Collector Agent → Log Backend
- Log UI → Log Backend
- Alerting → (Log Backend или метрики) + уведомления (email/чат)

---

## 7) Политика безопасности логов

### 7.1. Что считаем чувствительными данными
- токены, пароли, ключи доступа (в т.ч. S3), cookies, Authorization headers;
- персональные данные клиентов (ФИО, телефон, адрес);
- финансовые данные (полные суммы можно ограничить/маскировать);
- содержимое payload (тела запросов/ответов), если там могут быть PII.

### 7.2. Правила маскирования и исключения
- Запрет логировать:
  - `Authorization`, `Set-Cookie`, токены, секреты.
- Маскировать:
  - `customer_id`/`user_id` — хранить как хэш/псевдоидентификатор при необходимости.
- Ошибки:
  - логировать тип и код ошибки, но не полный stacktrace с секретами (stacktrace допустим, но без контента запросов).
- Ввести “allowlist полей” для логирования вместо “log everything”.

### 7.3. Доступ
- Только сотрудники компании по SSO/учётке.
- RBAC:
  - Поддержка: поиск по `order_id`, чтение ограниченного набора полей.
  - Разработчики: расширенный доступ (но без секретов).
  - Админы: управление индексами/ретеншном.
- Доступ к prod-логам — отдельно и строже (MFA/внутренняя сеть/VPN).

### 7.4. Защита каналов
- TLS от агентов до backend.
- Шифрование at rest.
- Аудит действий (кто что искал/скачивал, если система поддерживает).

---

## 8) Политика хранения логов

### 8.1. Разделение по системам/окружениям
- Отдельные индексы/тенанты (или labels) по:
  - `env` (dev/release/prod),
  - `service` (shop-api, crm-api, mes-api, rabbitmq).
- Это упрощает доступы и ретеншн.

### 8.2. Сроки хранения (пример, можно уточнить у бизнеса)
- **prod**:
  - INFO/WARN: 30 дней
  - ERROR: 90 дней (для расследования повторяющихся проблем)
- **release/dev**:
  - 7–14 дней

### 8.3. Ограничения по объёму
- Ввести лимиты объёма в сутки по окружению/сервису.
- Ограничить размер одного сообщения лога (например, <= 10–20 КБ).
- Включить ротацию и компрессию.

---

## 9) Превращение сбора логов в систему анализа

### 9.1. Алертинг (нужно)
Минимальный набор алертов по логам (и/или связанный с метриками):
- Всплеск ERROR по сервису (например, > N/мин или рост в X раз).
- Повторяющиеся ошибки одной сигнатуры (один и тот же error_type).
- Рост событий RETRY/DLQ по заказам/очередям.
- Частые 409/CONFLICT на claim заказа (признак гонок или неправильной логики).
- Ошибки доступа к S3 (403/404/timeout).
- Ошибки БД: “too many connections”, deadlock detected.

### 9.2. Поиск аномалий (желательно)
Примеры детектов:
- “Созданий заказов было 4/сек, стало 10 000/сек” → подозрение на DDoS или баг клиента.
- Резкий рост `SUBMITTED` без роста `PRICE_CALCULATED` → проблема в расчёте/очереди.
- Резкий рост времени `query_duration_ms` на дашборде MES → деградация БД или индексов.
- Рост доли заказов, которые переходят в RETRY/DLQ.

### 9.3. Практики
- Дашборды по log-based метрикам (например, error rate по типам).
- Runbook на каждый P1 алерт: “куда смотреть, что проверить, как эскалировать”.
- Регулярный разбор топ‑ошибок (weekly): что чаще ломается, что чинить в первую очередь.
